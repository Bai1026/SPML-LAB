{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34010e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0cb0704e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n",
      "519\n",
      "up\n",
      "1844\n",
      "on\n",
      "2230\n",
      "off\n",
      "2370\n",
      "down\n",
      "2371\n",
      "on\n",
      "2391\n",
      "off\n",
      "2505\n",
      "_unknown_\n",
      "2587\n",
      "on\n",
      "2614\n",
      "_unknown_\n",
      "2624\n",
      "there's 10 labels not being yes\n",
      "\n",
      "\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         off       0.00      0.00      0.00       257\n",
      "          no       0.00      0.00      0.00       257\n",
      "        left       0.00      0.00      0.00       253\n",
      "        stop       0.00      0.00      0.00       251\n",
      "        down       0.00      0.00      0.00       267\n",
      "          up       0.00      0.00      0.00       252\n",
      "         yes       0.00      0.00      0.00       262\n",
      "   _silence_       0.00      0.00      0.00       246\n",
      "          go       0.00      0.00      0.00       259\n",
      "       right       0.00      0.00      0.00       249\n",
      "   _unknown_       0.00      0.00      0.00       272\n",
      "          on       0.08      1.00      0.15       256\n",
      "\n",
      "    accuracy                           0.08      3081\n",
      "   macro avg       0.01      0.08      0.01      3081\n",
      "weighted avg       0.01      0.08      0.01      3081\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "with open('./fbank_to_KS/test_predict.txt', 'r') as file:\n",
    "    pred_lines = file.readlines()\n",
    "\n",
    "with open('./fbank_to_KS/test_truth.txt', 'r') as file:\n",
    "    true_lines = file.readlines()\n",
    "\n",
    "    \n",
    "pred_data = [line.strip().split() for line in pred_lines]\n",
    "true_data = [line.strip().split() for line in true_lines]\n",
    "\n",
    "filenames, pred_labels = zip(*pred_data)\n",
    "filenames, true_labels = zip(*true_data)\n",
    "# print(\"predicted: \", pred_labels, end='\\n\\n\\n' )\n",
    "# print(\"true: \", true_labels, end='\\n\\n\\n')\n",
    "\n",
    "count = 0\n",
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for label_1, label_2 in zip(pred_labels, true_labels):\n",
    "    total += 1\n",
    "    if label_1 == label_2 and label_1 != \"yes\":\n",
    "        print(label_1, label_2)\n",
    "        num += 1\n",
    "\n",
    "    if label_1 != \"yes\":\n",
    "        print(label_1)\n",
    "        count += 1\n",
    "        print(total)\n",
    "\n",
    "print(f\"there're {count} labels not being yes\\n\\n\")\n",
    "print(num)\n",
    "\n",
    "# 生成分类报告\n",
    "report = classification_report(true_labels, pred_labels, target_names=list(set(true_labels)))\n",
    "# report = classification_report(true_labels, pred_labels, target_names=list(set(true_labels)), zero_division=1)\n",
    "\n",
    "\n",
    "# 打印分类报告\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a3b28f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/u9655801/hw/hw2/s3prl/s3prl/result/downstream'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da41c2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/u9655801/hw/hw2/s3prl/s3prl/result/downstream/wav2vec2_to_KS\n"
     ]
    }
   ],
   "source": [
    "cd ./wav2vec2_to_KS/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8df09564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/u9655801/hw/hw2/s3prl/s3prl/result/downstream\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73710ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
